{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1195e3",
   "metadata": {},
   "source": [
    "# Depresjon - basic feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc66e36",
   "metadata": {},
   "source": [
    "This notebook aims to recreate feature engineering for Depresjon dataset from paper \"Comparison of Night, Day and 24 h Motor Activity Data for the Classification of Depressive Episodes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18cca4",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407d435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa17838",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91325e",
   "metadata": {},
   "source": [
    "First, we have to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5d992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./depresjon_data\"\n",
    "condition_dir = os.path.join(data_dir, \"condition\")\n",
    "control_dir = os.path.join(data_dir, \"control\")\n",
    "scores_file = os.path.join(data_dir, \"scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53d004",
   "metadata": {},
   "source": [
    "`condition` and `control` directories contain CSV files with measurements, one file per person. For example, `condition_1.csv` contains measurements for patient 1 diagnosed with depression.\n",
    "\n",
    "Those files are read into a list of dataframes, since this makes them easy to process later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f8bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [pd.read_csv(os.path.join(condition_dir, filename)) for filename in os.listdir(condition_dir)]\n",
    "controls = [pd.read_csv(os.path.join(control_dir, filename)) for filename in os.listdir(control_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb02beb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-07 12:00:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-07 12:01:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-07 12:02:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-07 12:03:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-07 12:04:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp        date  activity\n",
       "0  2003-05-07 12:00:00  2003-05-07         0\n",
       "1  2003-05-07 12:01:00  2003-05-07       143\n",
       "2  2003-05-07 12:02:00  2003-05-07         0\n",
       "3  2003-05-07 12:03:00  2003-05-07        20\n",
       "4  2003-05-07 12:04:00  2003-05-07       166"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b4a55",
   "metadata": {},
   "source": [
    "The `scores.csv` file contains static information about patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7057e28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>days</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>afftype</th>\n",
       "      <th>melanch</th>\n",
       "      <th>inpatient</th>\n",
       "      <th>edu</th>\n",
       "      <th>marriage</th>\n",
       "      <th>work</th>\n",
       "      <th>madrs1</th>\n",
       "      <th>madrs2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition_1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>35-39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition_2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>40-44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>45-49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>condition_4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>25-29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>condition_5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>50-54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        number  days  gender    age  afftype  melanch  inpatient    edu  \\\n",
       "0  condition_1    11       2  35-39      2.0      2.0        2.0   6-10   \n",
       "1  condition_2    18       2  40-44      1.0      2.0        2.0   6-10   \n",
       "2  condition_3    13       1  45-49      2.0      2.0        2.0   6-10   \n",
       "3  condition_4    13       2  25-29      2.0      2.0        2.0  11-15   \n",
       "4  condition_5    13       2  50-54      2.0      2.0        2.0  11-15   \n",
       "\n",
       "   marriage  work  madrs1  madrs2  \n",
       "0       1.0   2.0    19.0    19.0  \n",
       "1       2.0   2.0    24.0    11.0  \n",
       "2       2.0   2.0    24.0    25.0  \n",
       "3       1.0   1.0    20.0    16.0  \n",
       "4       2.0   2.0    26.0    26.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data = pd.read_csv(scores_file)\n",
    "static_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10090942",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d25130",
   "metadata": {},
   "source": [
    "We have the data loaded, now we can explore it: check number of measurements, number of columns, their types, missing values etc. First the data for time series will be checked, then for the static data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea91d9",
   "metadata": {},
   "source": [
    "### Number of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38950494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number: 23\n",
      "Control number: 32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = [\"Condition\", \"Control\"]\n",
    "ys = [len(conditions), len(controls)]\n",
    "\n",
    "print(f\"Condition number: {len(conditions)}\")\n",
    "print(f\"Control number: {len(controls)}\")\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "plt.xlabel(\"Group\")\n",
    "plt.ylabel(\"Patients\")\n",
    "plt.title(\"Number of patients per group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb3711",
   "metadata": {},
   "source": [
    "We definitely have quite heavy imbalance, the control group being about 50% larger than the condition group. This influences many metrics and should be taken into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddef373",
   "metadata": {},
   "source": [
    "### Measurements number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f13a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       23.000000\n",
       "mean     23987.652174\n",
       "std       5748.966513\n",
       "min      19299.000000\n",
       "25%      21463.000000\n",
       "50%      21648.000000\n",
       "75%      23117.000000\n",
       "max      41847.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_rows = pd.Series([len(df) for df in conditions])\n",
    "condition_rows.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa356b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       32.000000\n",
       "mean     31874.687500\n",
       "std      12228.922745\n",
       "min      20490.000000\n",
       "25%      22258.500000\n",
       "50%      28257.000000\n",
       "75%      33683.000000\n",
       "max      65407.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_rows = pd.Series([len(df) for df in controls])\n",
    "control_rows.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bc099",
   "metadata": {},
   "source": [
    "We have greatly varying number of measurements for both condition and control group. In general measurements for control group are longer, but also more varied (both mean and standard deviation are higher). For fair assessment, where each patient gets the same chance to influence the model, the measurements should be of equal length for all cases. However, for calculating aggregations (e.g. mean / median value) this may not be necessary, since they typically reduce the data to a single number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda489d",
   "metadata": {},
   "source": [
    "### Columns and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7b75e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-07 12:00:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-07 12:01:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-07 12:02:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-07 12:03:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-07 12:04:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp        date  activity\n",
       "0  2003-05-07 12:00:00  2003-05-07         0\n",
       "1  2003-05-07 12:01:00  2003-05-07       143\n",
       "2  2003-05-07 12:02:00  2003-05-07         0\n",
       "3  2003-05-07 12:03:00  2003-05-07        20\n",
       "4  2003-05-07 12:04:00  2003-05-07       166"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c445ffa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    object\n",
       "date         object\n",
       "activity      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[0].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fefbc",
   "metadata": {},
   "source": [
    "For measurement files we have 3 columns:\n",
    "- timestamp with precise measurement date and time, with 1 minute measurement resolution\n",
    "- date, information already included in the timestamp\n",
    "- activity, the time series value\n",
    "\n",
    "Data types of columns are definitely wrong - `timestamp` should be a proper timestamp and the `date` column is redundant. This will be fixed in the preprocessing section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e542e8",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934cb6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_NaNs = pd.Series([df[\"activity\"].isna().sum() for df in conditions])\n",
    "condition_NaNs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4296a4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_NaNs = pd.Series([df[\"activity\"].isna().sum() for df in controls])\n",
    "control_NaNs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba2b9b",
   "metadata": {},
   "source": [
    "We have exactly 0 missing values for the dependent variable, activity. This means that the data was accurately gathered for all patients for the entire duration of measurement period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62dadb7",
   "metadata": {},
   "source": [
    "### Static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829cda63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>days</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>afftype</th>\n",
       "      <th>melanch</th>\n",
       "      <th>inpatient</th>\n",
       "      <th>edu</th>\n",
       "      <th>marriage</th>\n",
       "      <th>work</th>\n",
       "      <th>madrs1</th>\n",
       "      <th>madrs2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition_1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>35-39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition_2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>40-44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>45-49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>condition_4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>25-29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>condition_5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>50-54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        number  days  gender    age  afftype  melanch  inpatient    edu  \\\n",
       "0  condition_1    11       2  35-39      2.0      2.0        2.0   6-10   \n",
       "1  condition_2    18       2  40-44      1.0      2.0        2.0   6-10   \n",
       "2  condition_3    13       1  45-49      2.0      2.0        2.0   6-10   \n",
       "3  condition_4    13       2  25-29      2.0      2.0        2.0  11-15   \n",
       "4  condition_5    13       2  50-54      2.0      2.0        2.0  11-15   \n",
       "\n",
       "   marriage  work  madrs1  madrs2  \n",
       "0       1.0   2.0    19.0    19.0  \n",
       "1       2.0   2.0    24.0    11.0  \n",
       "2       2.0   2.0    24.0    25.0  \n",
       "3       1.0   1.0    20.0    16.0  \n",
       "4       2.0   2.0    26.0    26.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4510f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number        object\n",
       "days           int64\n",
       "gender         int64\n",
       "age           object\n",
       "afftype      float64\n",
       "melanch      float64\n",
       "inpatient    float64\n",
       "edu           object\n",
       "marriage     float64\n",
       "work         float64\n",
       "madrs1       float64\n",
       "madrs2       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86b7b342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number ['condition_1' 'condition_2' 'condition_3' 'condition_4' 'condition_5'\n",
      " 'condition_6' 'condition_7' 'condition_8' 'condition_9' 'condition_10'\n",
      " 'condition_11' 'condition_12' 'condition_13' 'condition_14'\n",
      " 'condition_15' 'condition_16' 'condition_17' 'condition_18'\n",
      " 'condition_19' 'condition_20' 'condition_21' 'condition_22'\n",
      " 'condition_23' 'control_1' 'control_2' 'control_3' 'control_4'\n",
      " 'control_5' 'control_6' 'control_7' 'control_8' 'control_9' 'control_10'\n",
      " 'control_11' 'control_12' 'control_13' 'control_14' 'control_15'\n",
      " 'control_16' 'control_17' 'control_18' 'control_19' 'control_20'\n",
      " 'control_21' 'control_22' 'control_23' 'control_24' 'control_25'\n",
      " 'control_26' 'control_27' 'control_28' 'control_29' 'control_30'\n",
      " 'control_31' 'control_32']\n",
      "days [11 18 13  7  5  9 14 12 16  8 20]\n",
      "gender [2 1]\n",
      "age ['35-39' '40-44' '45-49' '25-29' '50-54' '20-24' '60-64' '55-59' '30-34'\n",
      " '65-69']\n",
      "afftype [ 2.  1.  3. nan]\n",
      "melanch [ 2. nan  1.]\n",
      "inpatient [ 2.  1. nan]\n",
      "edu ['6-10' '11-15' '16-20' ' ' nan]\n",
      "marriage [ 1.  2. nan]\n",
      "work [ 2.  1. nan]\n",
      "madrs1 [19. 24. 20. 26. 18. 28. 25. 14. 13. 17. 27. 29. nan]\n",
      "madrs2 [19. 11. 25. 16. 26. 15. 21. 24. 13. 18. 17. 28. 23. nan]\n"
     ]
    }
   ],
   "source": [
    "for col in static_data.columns:\n",
    "    print(col, static_data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd786a",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- all data types seem correct\n",
    "- `number` is essentially an index for patients and should not be used as a feature\n",
    "- `days` indicate the number of data collection days, but this information is already included in the time series timestamps\n",
    "- `gender` is correct, but doesn't follow the usual convention of 0-1 values for binary features\n",
    "- `age` should be preprocessed to integers (e.g. `0` for <50 years, `1` for >= 50 years) for classification\n",
    "- `afftype` and `melanch` indicate the clinical state observations for depressed patients and are NaN for non-depressed controls\n",
    "- `edu`, `marriage` and `work` explain socioeconomic status of the patient\n",
    "- `madrs1` and `madrs2` are MADRS score for patients with condition at the beginning and at the end of measurements; they are not used for classification, but they could be used as regression targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c505517",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f050c4",
   "metadata": {},
   "source": [
    "In the paper several steps of feature engineering are introduced. They need to be performed, as the typical models for tabular data like Random Forest are used. This approach allows usage of classical ML algorithms on time series data, while also indirectly incorporating time dependencies in form of features derived from the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1751c47",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd07fbf",
   "metadata": {},
   "source": [
    "**Warning 1**: I've found out that the paper is actually inconsistent in what it says and does in the preprocessing. It states that:\n",
    "\"For the pre-processing stage, the next step are proposed. Since the total amount of data recorded for each subject is different, a new subset of data is extracted, adjusting the number of observations to be equal for each subject. Theh, from the new set of data, a segmentation is applied to form one hour data intervals. This segmentation allowed the classification of depressive episodes per hour.\n",
    "\n",
    "Therefore, based on the hourly segmentation, three different subsets are constructed; night motor activity (from 21 to 7 h taking into account the sunrise standard hours) [21], day motor activity (from 8 to 20 h) and finally all day motor activity with the total day hours. The number of observations contained in each dataset is shown in Table 1. After separated the data into day, night and 24 h data were cleaned from missing data.\"\n",
    "\n",
    "According to this, we should:\n",
    "- trim observations to the length of the shortest one, forming \"new set of data\" with same number of observations per subject\n",
    "- segment into 1-hour intervals, calculating average activity\n",
    "- create night dataset, day dataset and dataset with all observations\n",
    "\n",
    "According to the paper, they got the following number of hourly observations:\n",
    "- day: 14168\n",
    "- night: 11945\n",
    "- full data: 26113\n",
    "\n",
    "But this number is wrong. This is approximately the number of raw observations in the dataset, not number of hour segments. In addition, to make sure that night and day data has the same length, it should be trimmed to the same length after splitting. Corrected process:\n",
    "- segment data for each patient into 1-hour intervals, calculating average activity\n",
    "- create night dataset, day dataset and dataset with all observations\n",
    "- trim observations in each dataset to the length of the shortest one\n",
    "\n",
    "This way, we arrive at the following sequences lengths:\n",
    "- day: 9845\n",
    "- night: 7865\n",
    "- full data: 17710"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b915270",
   "metadata": {},
   "source": [
    "**Warning 2:** it's not precisely specified how the features in the frequency domain are calculated. We assume that:\n",
    "1) We group samples from the same hour (in time domain)\n",
    "2) Calculate FFT for each hour separately\n",
    "3) Calculate PSD from FFT data for each hour separately\n",
    "4) Concatenate PSD results as a vector\n",
    "\n",
    "This results in the same data length as the time data segmented into hours.\n",
    "\n",
    "Also the paper makes a few errors with the PSD. The power spectral density is the whole spectrum, and the paper reduces it to a single number per signal using the formula $P = \\lim_{T -> \\infty} \\frac{1}{T} \\int_0^T |x(k)|^2 dx$. The paper call this energy, but this is actually the **total power** of the signal for the given sample. The frequency domain is therefore the power domain really, and statistics calculated from it are calculated from hourly total powers of the activity.\n",
    "\n",
    "For consistency with the paper, we'll use names \"frequency domain\" and \"PSD\" in the following analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fffc07e",
   "metadata": {},
   "source": [
    "First, correct the data type of `timestamp` column and drop the redundant `date` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711fd096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-07 12:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-07 12:01:00</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-07 12:02:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-07 12:03:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-07 12:04:00</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  activity\n",
       "0 2003-05-07 12:00:00         0\n",
       "1 2003-05-07 12:01:00       143\n",
       "2 2003-05-07 12:02:00         0\n",
       "3 2003-05-07 12:03:00        20\n",
       "4 2003-05-07 12:04:00       166"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in (conditions + controls):\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "for df in (conditions + controls):\n",
    "    if \"date\" in df.columns:\n",
    "        df.drop(\"date\", axis=1, inplace=True)\n",
    "\n",
    "conditions[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eca33c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    datetime64[ns]\n",
       "activity              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controls[1].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3547b",
   "metadata": {},
   "source": [
    "Next, calculate segmented values. For time domain, just calculate hourly means. For frequency domain, calculate FFT and PSD, obtaining total power, for each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acbcfbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ae20188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_power(df: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Applies FFT and PSD to the input, calculating total power.\n",
    "    \"\"\"\n",
    "    df = df.to_numpy()\n",
    "    df = fft(df)  # returns np.ndarray\n",
    "    df = np.mean(np.square(np.abs(df)))  # PSD\n",
    "    return pd.Series(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73ce8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_hour(df: pd.DataFrame, domain: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    df: DataFrame with columns \"datetime\" and \"activity\"\n",
    "    domain: \"time\" or \"freq\"\n",
    "    \"\"\"\n",
    "    # group by hour\n",
    "    grouped = df.groupby([pd.Grouper(key=\"timestamp\", freq=\"H\")])\n",
    "    \n",
    "    # aggregate in the proper domain\n",
    "    if domain == \"time\":\n",
    "        grouped = grouped.mean()\n",
    "    elif domain == \"freq\":\n",
    "        grouped = grouped.agg(total_power)\n",
    "    else:\n",
    "        raise ValueError(f'Domain should be \"time\" or \"freq\", got \"{domain}\"')\n",
    "    \n",
    "    # change index back to RangeIndex, since it became TimeIndex during grouping\n",
    "    grouped.reset_index(inplace=True)\n",
    "    \n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c957c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_time_preprocessed = [group_by_hour(df, \"time\") for df in conditions]\n",
    "controls_time_preprocessed = [group_by_hour(df, \"time\") for df in controls]\n",
    "\n",
    "conditions_freq_preprocessed = [group_by_hour(df, \"freq\") for df in conditions]\n",
    "controls_freq_preprocessed = [group_by_hour(df, \"freq\") for df in controls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6ad4ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-07 12:00:00</td>\n",
       "      <td>346.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-07 13:00:00</td>\n",
       "      <td>284.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-07 14:00:00</td>\n",
       "      <td>279.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-07 15:00:00</td>\n",
       "      <td>218.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-07 16:00:00</td>\n",
       "      <td>238.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2003-05-23 11:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2003-05-23 12:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2003-05-23 13:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2003-05-23 14:00:00</td>\n",
       "      <td>11.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2003-05-23 15:00:00</td>\n",
       "      <td>79.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp    activity\n",
       "0   2003-05-07 12:00:00  346.550000\n",
       "1   2003-05-07 13:00:00  284.566667\n",
       "2   2003-05-07 14:00:00  279.183333\n",
       "3   2003-05-07 15:00:00  218.783333\n",
       "4   2003-05-07 16:00:00  238.550000\n",
       "..                  ...         ...\n",
       "383 2003-05-23 11:00:00    0.000000\n",
       "384 2003-05-23 12:00:00    0.000000\n",
       "385 2003-05-23 13:00:00    0.000000\n",
       "386 2003-05-23 14:00:00   11.400000\n",
       "387 2003-05-23 15:00:00   79.500000\n",
       "\n",
       "[388 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions_time_preprocessed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a71fdd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-07 12:00:00</td>\n",
       "      <td>11191987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-07 13:00:00</td>\n",
       "      <td>8078860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-07 14:00:00</td>\n",
       "      <td>9051577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-07 15:00:00</td>\n",
       "      <td>8124159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-07 16:00:00</td>\n",
       "      <td>7685663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2003-05-23 11:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2003-05-23 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2003-05-23 13:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2003-05-23 14:00:00</td>\n",
       "      <td>145540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2003-05-23 15:00:00</td>\n",
       "      <td>1162790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp    activity\n",
       "0   2003-05-07 12:00:00  11191987.0\n",
       "1   2003-05-07 13:00:00   8078860.0\n",
       "2   2003-05-07 14:00:00   9051577.0\n",
       "3   2003-05-07 15:00:00   8124159.0\n",
       "4   2003-05-07 16:00:00   7685663.0\n",
       "..                  ...         ...\n",
       "383 2003-05-23 11:00:00         0.0\n",
       "384 2003-05-23 12:00:00         0.0\n",
       "385 2003-05-23 13:00:00         0.0\n",
       "386 2003-05-23 14:00:00    145540.0\n",
       "387 2003-05-23 15:00:00   1162790.0\n",
       "\n",
       "[388 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions_freq_preprocessed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d9f86",
   "metadata": {},
   "source": [
    "Lastly, create separate night and day datasets in addition to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a29b7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_night_day_division(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    night_df = df.loc[(df[\"timestamp\"].dt.hour >= 21) | (df[\"timestamp\"].dt.hour < 8)]\n",
    "    day_df = df.loc[(df[\"timestamp\"].dt.hour >= 8) & (df[\"timestamp\"].dt.hour < 21)]\n",
    "    return night_df, day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "785d20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_time_night = []\n",
    "conditions_time_day = []\n",
    "conditions_time_all = []\n",
    "\n",
    "controls_time_night = []\n",
    "controls_time_day = []\n",
    "controls_time_all = []\n",
    "\n",
    "for df in conditions_time_preprocessed:\n",
    "    night_df, day_df = get_night_day_division(df)\n",
    "    conditions_time_night.append(night_df)\n",
    "    conditions_time_day.append(day_df)\n",
    "    conditions_time_all.append(df)\n",
    "\n",
    "for df in controls_time_preprocessed:\n",
    "    night_df, day_df = get_night_day_division(df)\n",
    "    controls_time_night.append(night_df)\n",
    "    controls_time_day.append(day_df)\n",
    "    controls_time_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ee8f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_freq_night = []\n",
    "conditions_freq_day = []\n",
    "conditions_freq_all = []\n",
    "\n",
    "controls_freq_night = []\n",
    "controls_freq_day = []\n",
    "controls_freq_all = []\n",
    "\n",
    "for df in conditions_freq_preprocessed:\n",
    "    night_df, day_df = get_night_day_division(df)\n",
    "    conditions_freq_night.append(night_df)\n",
    "    conditions_freq_day.append(day_df)\n",
    "    conditions_freq_all.append(df)\n",
    "\n",
    "for df in controls_freq_preprocessed:\n",
    "    night_df, day_df = get_night_day_division(df)\n",
    "    controls_freq_night.append(night_df)\n",
    "    controls_freq_day.append(day_df)\n",
    "    controls_freq_all.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9308a0",
   "metadata": {},
   "source": [
    "Trim to the same number of 1-hour segments, so we have equal length sequences for night, day and all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "daa0e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length_night = min([len(df) for df in conditions_time_night + controls_time_night])\n",
    "min_length_day = min([len(df) for df in conditions_time_day + controls_time_day])\n",
    "min_length_all = min([len(df) for df in conditions_time_all + controls_time_all])\n",
    "\n",
    "conditions_time_trimmed = {\n",
    "    \"night\": [df[:min_length_night] for df in conditions_time_night],\n",
    "    \"day\": [df[:min_length_day] for df in conditions_time_day],\n",
    "    \"all\": [df[:min_length_all] for df in conditions_time_all]\n",
    "}\n",
    "\n",
    "controls_time_trimmed = {\n",
    "    \"night\": [df[:min_length_night] for df in controls_time_night],\n",
    "    \"day\": [df[:min_length_day] for df in controls_time_day],\n",
    "    \"all\": [df[:min_length_all] for df in controls_time_all]\n",
    "}\n",
    "\n",
    "\n",
    "conditions_freq_trimmed = {\n",
    "    \"night\": [df[:min_length_night] for df in conditions_freq_night],\n",
    "    \"day\": [df[:min_length_day] for df in conditions_freq_day],\n",
    "    \"all\": [df[:min_length_all] for df in conditions_freq_all]\n",
    "}\n",
    "\n",
    "controls_freq_trimmed = {\n",
    "    \"night\": [df[:min_length_night] for df in controls_freq_night],\n",
    "    \"day\": [df[:min_length_day] for df in controls_freq_day],\n",
    "    \"all\": [df[:min_length_all] for df in controls_freq_all]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2571c6",
   "metadata": {},
   "source": [
    "Let's check the number of hour segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3610590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 9845\n",
      "Night: 7865\n",
      "Full data: 17710\n"
     ]
    }
   ],
   "source": [
    "night_observations = sum([len(df) for df in conditions_time_trimmed[\"night\"] + controls_time_trimmed[\"night\"]])\n",
    "day_observations = sum([len(df) for df in conditions_time_trimmed[\"day\"] + controls_time_trimmed[\"day\"]])\n",
    "all_observations= sum([len(df) for df in conditions_time_trimmed[\"all\"] + controls_time_trimmed[\"all\"]])\n",
    "\n",
    "print(f\"Day: {day_observations}\")\n",
    "print(f\"Night: {night_observations}\")\n",
    "print(f\"Full data: {day_observations + night_observations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffb113",
   "metadata": {},
   "source": [
    "As you can see, the number of segments is very different than stated in the paper. However, that was probably just a mistake in specifying the table contents and authors got similiar numbers of actual hourly segments as here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118bb4a",
   "metadata": {},
   "source": [
    "Before further processing it will come in handy to work on regular Numpy arrays instead of lists of DataFrames. We will have 1 row per patient, with columns indicating measurements (short and wide matrix). We'll process time and frequency data separatly and combine the calculated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38581f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"time\": {}, \n",
    "    \"freq\": {}\n",
    "}\n",
    "\n",
    "for domain in [\"time\", \"freq\"]:\n",
    "    for part in [\"night\", \"day\", \"all\"]:\n",
    "        X = [df[\"activity\"].values for df in conditions_time_trimmed[part]] + \\\n",
    "            [df[\"activity\"].values for df in controls_time_trimmed[part]]\n",
    "        X = np.vstack(X)\n",
    "        \n",
    "        y = np.zeros(X.shape[0])\n",
    "        y[:len(conditions_time_trimmed[part]) + 1] = 1\n",
    "\n",
    "        data[domain][\"X_\" + part] = X\n",
    "        data[domain][\"y_\" + part] = y\n",
    "\n",
    "# each one contains keys: X_night, y_night, X_day, y_day, X_all, y_all\n",
    "time_data = data[\"time\"]\n",
    "freq_data = data[\"freq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a44110",
   "metadata": {},
   "source": [
    "Make sure that the data is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a06f4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.15333333e+01, 3.24500000e+01, 1.48733333e+02, 8.00000000e+00,\n",
       "        4.08333333e+00, 7.06666667e+00, 4.03333333e+00, 1.22166667e+01,\n",
       "        9.66666667e-01, 1.00000000e+01, 1.37000000e+01, 1.20050000e+02,\n",
       "        4.65166667e+01, 6.78666667e+01, 6.97000000e+01, 2.22500000e+01,\n",
       "        1.10166667e+01, 2.08333333e+00, 1.26500000e+01, 4.51666667e+00,\n",
       "        6.43333333e+00, 5.66666667e+00, 1.78116667e+02, 5.82000000e+01,\n",
       "        3.67000000e+01, 1.00616667e+02, 9.86333333e+01, 7.71666667e+00,\n",
       "        3.28333333e+00, 3.70000000e+00, 5.83333333e-01, 1.96666667e+00,\n",
       "        1.77833333e+01, 4.76666667e+01, 7.99666667e+01, 8.54833333e+01,\n",
       "        2.76666667e+00, 9.16666667e-01, 4.08333333e+00, 6.51666667e+00,\n",
       "        2.03666667e+01, 7.95000000e+00, 1.37333333e+01, 1.08666667e+01,\n",
       "        5.21500000e+01, 4.39666667e+01, 1.11233333e+02, 2.76666667e+00,\n",
       "        2.66666667e+00, 1.24500000e+01, 5.25000000e+00, 9.81666667e+00,\n",
       "        9.68333333e+00, 9.68333333e+00, 9.86666667e+00, 1.40200000e+02,\n",
       "        5.63666667e+01, 3.18000000e+01, 5.20000000e+01, 1.00483333e+02,\n",
       "        1.57333333e+01, 9.53333333e+00, 3.00000000e-01, 7.30000000e+00,\n",
       "        1.25333333e+01, 1.64500000e+01, 6.60500000e+01, 1.32216667e+02,\n",
       "        9.90000000e+00, 3.78333333e+00, 2.91666667e+00, 1.40166667e+01,\n",
       "        5.63333333e+00, 2.57500000e+01, 2.50000000e+00, 1.73166667e+01,\n",
       "        6.57333333e+01, 2.06883333e+02, 1.87466667e+02, 7.47500000e+01,\n",
       "        8.90833333e+01, 9.90000000e+00, 9.00000000e-01, 3.60000000e+00,\n",
       "        3.56666667e+00, 6.45000000e+00, 9.56666667e+00, 1.15833333e+01,\n",
       "        1.32616667e+02, 1.49733333e+02, 1.05783333e+02, 8.41666667e+00,\n",
       "        1.92666667e+01, 1.39833333e+01, 7.91666667e+00, 6.18333333e+00,\n",
       "        1.71166667e+01, 2.62500000e+01, 1.77350000e+02, 5.76166667e+01,\n",
       "        7.06833333e+01, 6.17333333e+01, 9.84000000e+01, 1.34666667e+01,\n",
       "        8.01666667e+00, 7.06666667e+00, 1.78333333e+01, 9.16666667e-01,\n",
       "        7.98333333e+00, 8.35000000e+00, 1.20533333e+02, 5.10166667e+01,\n",
       "        9.74833333e+01, 7.28833333e+01, 1.17333333e+01, 1.36000000e+01,\n",
       "        6.45000000e+00, 6.96666667e+00, 1.07666667e+01, 9.45000000e+00,\n",
       "        4.70666667e+01, 9.97500000e+01, 3.26500000e+01, 9.69333333e+01,\n",
       "        3.95000000e+00, 9.03333333e+00, 4.91666667e+00, 4.21666667e+00,\n",
       "        6.91666667e+00, 1.75500000e+01, 1.18000000e+01, 2.53166667e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.33333333e-01],\n",
       "       [2.60433333e+02, 3.93850000e+02, 2.25500000e+01, 1.59833333e+01,\n",
       "        5.46666667e+00, 2.71500000e+01, 1.06833333e+01, 7.33333333e+00,\n",
       "        9.13333333e+00, 5.76666667e+00, 2.13033333e+02, 4.43233333e+02,\n",
       "        6.02700000e+02, 7.82666667e+01, 1.58500000e+01, 2.03333333e+01,\n",
       "        9.38333333e+00, 1.23333333e+01, 2.04166667e+01, 3.21500000e+01,\n",
       "        1.67333333e+01, 4.94166667e+01, 5.03516667e+02, 4.42050000e+02,\n",
       "        7.26833333e+01, 9.67666667e+01, 1.22333333e+01, 2.18333333e+00,\n",
       "        7.45000000e+00, 7.05000000e+00, 2.17666667e+01, 8.60000000e+00,\n",
       "        3.09766667e+02, 4.51766667e+02, 5.09433333e+02, 1.29000000e+02,\n",
       "        1.97666667e+01, 6.66666667e+00, 1.32333333e+01, 9.16666667e+00,\n",
       "        9.20000000e+00, 1.54833333e+01, 4.29166667e+01, 2.43533333e+02,\n",
       "        6.36716667e+02, 2.93683333e+02, 4.15550000e+02, 8.46666667e+00,\n",
       "        1.54833333e+01, 1.24500000e+01, 1.83833333e+01, 2.61000000e+01,\n",
       "        1.98166667e+01, 1.97833333e+01, 2.93166667e+01, 4.06383333e+02,\n",
       "        3.81933333e+02, 8.66666667e+00, 9.71666667e+00, 7.71666667e+00,\n",
       "        1.42333333e+01, 2.54666667e+01, 5.60666667e+01, 5.94333333e+01,\n",
       "        5.64333333e+01, 2.06216667e+02, 3.30083333e+02, 3.30750000e+02,\n",
       "        2.95500000e+01, 3.33500000e+01, 2.08500000e+01, 5.01666667e+00,\n",
       "        1.84333333e+01, 2.00666667e+01, 2.67000000e+01, 2.01000000e+01,\n",
       "        2.46183333e+02, 7.63416667e+02, 3.06983333e+02, 1.25000000e+01,\n",
       "        1.56500000e+01, 1.32166667e+01, 5.16666667e+00, 3.65000000e+00,\n",
       "        2.24000000e+01, 1.25000000e+01, 1.88333333e+01, 4.58833333e+01,\n",
       "        3.30083333e+02, 5.62666667e+01, 3.01500000e+01, 1.92500000e+01,\n",
       "        1.32333333e+01, 2.59166667e+01, 1.26333333e+01, 9.81666667e+00,\n",
       "        2.72166667e+01, 2.35833333e+01, 2.17816667e+02, 3.57050000e+02,\n",
       "        1.84766667e+02, 1.43666667e+01, 1.71333333e+01, 4.37000000e+01,\n",
       "        1.56000000e+01, 3.09833333e+01, 3.63666667e+01, 2.03000000e+01,\n",
       "        1.99166667e+01, 4.17833333e+01, 3.82483333e+02, 3.18116667e+02,\n",
       "        4.08083333e+02, 2.52450000e+02, 1.10166667e+01, 2.36333333e+01,\n",
       "        5.81666667e+00, 3.25500000e+01, 2.49666667e+01, 2.71500000e+01,\n",
       "        8.18666667e+01, 2.29000000e+02, 1.40550000e+02, 1.85166667e+01,\n",
       "        2.78166667e+01, 1.49666667e+01, 2.64333333e+01, 1.79166667e+01,\n",
       "        1.81166667e+01, 1.64666667e+01, 8.10000000e+01, 8.21166667e+01,\n",
       "        4.54266667e+02, 2.12750000e+02, 2.26166667e+01, 2.49166667e+01,\n",
       "        1.48666667e+01, 1.87333333e+01, 4.16666667e+00, 2.05666667e+01,\n",
       "        1.15833333e+01, 3.33833333e+01, 4.67666667e+01],\n",
       "       [3.92583333e+02, 5.11000000e+01, 5.47833333e+01, 6.96833333e+01,\n",
       "        2.66666667e+00, 1.37500000e+01, 4.48333333e+00, 1.20333333e+01,\n",
       "        5.11666667e+01, 7.09500000e+01, 5.61666667e+00, 2.30333333e+01,\n",
       "        2.15783333e+02, 6.00666667e+01, 6.51000000e+01, 2.30000000e+00,\n",
       "        1.11666667e+00, 9.45000000e+00, 7.66666667e+00, 8.26333333e+01,\n",
       "        5.70833333e+01, 7.25000000e+00, 2.19683333e+02, 1.52900000e+02,\n",
       "        9.86000000e+01, 5.67166667e+01, 7.20000000e+01, 8.67166667e+01,\n",
       "        8.16500000e+01, 6.16666667e-01, 1.04500000e+01, 0.00000000e+00,\n",
       "        2.40000000e+00, 3.02983333e+02, 4.04083333e+02, 2.43383333e+02,\n",
       "        5.02316667e+02, 3.19916667e+02, 2.98783333e+02, 7.29500000e+01,\n",
       "        1.49566667e+02, 0.00000000e+00, 7.00000000e+00, 4.90000000e+00,\n",
       "        3.60250000e+02, 3.65600000e+02, 2.65033333e+02, 2.14166667e+02,\n",
       "        1.30200000e+02, 1.07566667e+02, 1.01650000e+02, 0.00000000e+00,\n",
       "        8.31666667e+00, 5.86666667e+00, 5.68333333e+00, 1.38500000e+01,\n",
       "        2.57000000e+01, 2.06300000e+02, 1.36000000e+01, 7.41666667e+00,\n",
       "        3.18333333e+00, 4.00000000e+00, 6.26666667e+00, 1.78333333e+00,\n",
       "        7.68333333e+00, 1.15666667e+01, 1.17116667e+02, 1.10216667e+02,\n",
       "        3.01666667e+00, 1.27666667e+01, 3.06666667e+00, 1.07166667e+01,\n",
       "        5.31666667e+00, 5.31666667e+00, 3.33666667e+01, 8.21833333e+01,\n",
       "        5.06666667e+00, 2.34350000e+02, 1.60866667e+02, 5.06666667e+00,\n",
       "        6.66666667e-01, 9.50000000e+00, 1.10000000e+00, 1.08666667e+01,\n",
       "        5.91666667e+00, 4.70000000e+00, 1.01500000e+01, 6.28333333e+00,\n",
       "        2.38633333e+02, 1.28116667e+02, 2.08566667e+02, 8.31666667e+01,\n",
       "        7.11166667e+01, 3.77833333e+01, 8.77333333e+01, 1.16666667e+00,\n",
       "        1.22166667e+01, 4.66666667e-01, 4.95000000e+00, 1.91350000e+02,\n",
       "        6.02333333e+01, 1.88916667e+02, 4.86666667e+01, 4.60666667e+01,\n",
       "        0.00000000e+00, 7.78333333e+00, 0.00000000e+00, 2.10000000e+00,\n",
       "        7.11666667e+00, 3.81666667e+00, 5.01333333e+02, 4.45833333e+02,\n",
       "        3.79200000e+02, 2.27250000e+02, 3.88650000e+02, 1.03466667e+02,\n",
       "        2.57333333e+02, 1.24033333e+02, 4.31666667e+00, 3.23333333e+00,\n",
       "        0.00000000e+00, 2.35533333e+02, 3.10500000e+02, 1.75566667e+02,\n",
       "        3.19716667e+02, 3.63716667e+02, 9.40333333e+01, 8.77166667e+01,\n",
       "        3.10333333e+01, 6.62000000e+01, 1.03833333e+01, 8.83333333e-01,\n",
       "        3.02166667e+01, 1.32000000e+01, 2.64666667e+02, 4.20000000e+01,\n",
       "        7.11666667e+00, 4.11666667e+00, 9.26666667e+00, 1.19333333e+01,\n",
       "        6.56666667e+00, 1.04500000e+01, 5.76666667e+00],\n",
       "       [5.32350000e+02, 2.02416667e+02, 7.50333333e+01, 1.17666667e+01,\n",
       "        4.96333333e+01, 1.10333333e+01, 7.83333333e-01, 6.38333333e+00,\n",
       "        1.07166667e+01, 6.69666667e+01, 9.44666667e+01, 2.99533333e+02,\n",
       "        1.80083333e+02, 4.93500000e+01, 7.22166667e+01, 1.17166667e+01,\n",
       "        1.15000000e+00, 2.04833333e+01, 2.31666667e+00, 4.68333333e+00,\n",
       "        1.04000000e+01, 1.30600000e+02, 4.49750000e+02, 1.50816667e+02,\n",
       "        2.40466667e+02, 2.38816667e+02, 3.09166667e+01, 5.46666667e+00,\n",
       "        2.44833333e+01, 3.20000000e+00, 3.11666667e+00, 7.41666667e+00,\n",
       "        8.63833333e+01, 1.46983333e+02, 1.14266667e+02, 1.20050000e+02,\n",
       "        2.21616667e+02, 4.93333333e+01, 4.31666667e+00, 4.71666667e+00,\n",
       "        2.51666667e+00, 4.16666667e-01, 5.33333333e+00, 1.39500000e+01,\n",
       "        1.73550000e+02, 2.70050000e+02, 1.11100000e+02, 2.94333333e+02,\n",
       "        3.03766667e+02, 2.64900000e+02, 1.22933333e+02, 1.98000000e+01,\n",
       "        4.78333333e+00, 1.22000000e+01, 8.40000000e+00, 4.25833333e+01,\n",
       "        2.24150000e+02, 1.21983333e+02, 6.95666667e+01, 2.62000000e+01,\n",
       "        1.39000000e+01, 4.23333333e+00, 6.71666667e+00, 2.38333333e+00,\n",
       "        8.81666667e+00, 1.04816667e+02, 4.42650000e+02, 9.46833333e+01,\n",
       "        2.53383333e+02, 4.36500000e+01, 5.10500000e+01, 4.16666667e-01,\n",
       "        6.03333333e+00, 1.29000000e+01, 1.79333333e+01, 1.85666667e+01,\n",
       "        9.36166667e+01, 2.92600000e+02, 2.54166667e+02, 2.10466667e+02,\n",
       "        7.76833333e+01, 9.10333333e+01, 9.01666667e+00, 1.01333333e+01,\n",
       "        8.16666667e-01, 8.65000000e+00, 8.75000000e+00, 8.61333333e+01,\n",
       "        2.86283333e+02, 1.23050000e+02, 8.27333333e+01, 4.91666667e+01,\n",
       "        1.88166667e+01, 1.36500000e+01, 3.60000000e+00, 2.24833333e+01,\n",
       "        5.53333333e+00, 9.53333333e+00, 8.41666667e+01, 2.26783333e+02,\n",
       "        1.05866667e+02, 1.20200000e+02, 8.55000000e+00, 8.40000000e+00,\n",
       "        4.70000000e+00, 4.60000000e+00, 5.40000000e+00, 1.27833333e+01,\n",
       "        7.63000000e+01, 1.16733333e+02, 2.40083333e+02, 2.94500000e+02,\n",
       "        3.31433333e+02, 5.99666667e+01, 4.12333333e+01, 9.20000000e+00,\n",
       "        3.76666667e+00, 6.51666667e+00, 1.23833333e+01, 1.06666667e+01,\n",
       "        2.47833333e+01, 1.18916667e+02, 1.80566667e+02, 8.31666667e+01,\n",
       "        6.07500000e+01, 5.07833333e+01, 1.41166667e+01, 4.21666667e+00,\n",
       "        4.08333333e+00, 2.85333333e+01, 2.34666667e+01, 4.38333333e+00,\n",
       "        4.89500000e+01, 1.40733333e+02, 1.11900000e+02, 5.09000000e+01,\n",
       "        6.61166667e+01, 4.86333333e+01, 1.84833333e+01, 5.13333333e+00,\n",
       "        1.47333333e+01, 9.96666667e+00, 6.51666667e+00],\n",
       "       [3.09816667e+02, 1.14166667e+02, 3.58666667e+01, 5.06666667e+00,\n",
       "        1.01000000e+01, 5.26666667e+00, 3.79166667e+01, 6.83833333e+01,\n",
       "        2.69783333e+02, 2.44866667e+02, 1.44683333e+02, 2.51150000e+02,\n",
       "        3.67200000e+02, 3.85916667e+02, 4.72100000e+02, 2.51216667e+02,\n",
       "        1.90233333e+02, 2.94166667e+01, 5.55666667e+01, 3.73333333e+00,\n",
       "        1.04666667e+01, 2.75333333e+01, 1.93750000e+02, 4.17500000e+02,\n",
       "        2.68466667e+02, 4.77566667e+02, 1.42666667e+02, 2.80666667e+01,\n",
       "        4.58333333e+00, 1.38000000e+01, 9.98333333e+00, 8.55000000e+00,\n",
       "        4.01000000e+01, 2.39033333e+02, 1.62450000e+02, 1.59316667e+02,\n",
       "        3.06350000e+02, 8.32333333e+01, 1.35333333e+02, 1.94500000e+01,\n",
       "        1.26666667e+01, 8.63333333e+00, 1.68666667e+01, 2.52500000e+02,\n",
       "        2.93216667e+02, 1.63883333e+02, 8.40333333e+01, 2.77333333e+02,\n",
       "        1.03483333e+02, 2.81500000e+01, 1.17833333e+01, 4.35000000e+00,\n",
       "        3.03833333e+01, 1.12366667e+02, 1.22166667e+01, 1.13816667e+02,\n",
       "        1.36950000e+02, 3.29750000e+02, 6.55166667e+01, 2.96316667e+02,\n",
       "        1.81050000e+02, 3.26333333e+01, 1.61166667e+01, 1.50000000e+01,\n",
       "        2.04166667e+01, 1.84666667e+01, 2.50866667e+02, 2.57300000e+02,\n",
       "        1.09050000e+02, 6.08166667e+01, 5.20500000e+01, 2.25833333e+01,\n",
       "        2.24666667e+01, 3.47833333e+01, 5.60833333e+01, 1.82333333e+01,\n",
       "        6.63333333e+01, 5.28583333e+02, 3.13100000e+02, 2.46616667e+02,\n",
       "        2.74200000e+02, 1.38833333e+01, 1.75000000e+01, 8.68333333e+00,\n",
       "        1.58000000e+01, 7.46666667e+00, 8.21833333e+01, 6.66816667e+02,\n",
       "        3.47366667e+02, 2.26650000e+02, 1.49616667e+02, 1.88950000e+02,\n",
       "        5.34500000e+01, 8.96666667e+00, 1.66666667e+01, 1.46666667e+01,\n",
       "        8.33333333e+00, 1.31483333e+02, 3.04066667e+02, 2.26966667e+02,\n",
       "        1.87800000e+02, 1.29883333e+02, 1.75183333e+02, 2.24833333e+01,\n",
       "        1.08783333e+02, 1.00166667e+01, 7.76666667e+00, 9.46666667e+00,\n",
       "        5.47666667e+01, 9.01666667e+00, 3.91616667e+02, 3.32366667e+02,\n",
       "        4.01466667e+02, 6.20150000e+02, 2.91166667e+01, 7.88333333e+00,\n",
       "        6.46000000e+01, 1.96833333e+01, 2.12833333e+01, 1.80666667e+01,\n",
       "        4.00700000e+02, 2.33750000e+02, 2.95416667e+02, 1.22250000e+02,\n",
       "        1.52500000e+01, 1.42333333e+01, 2.53333333e+00, 2.88000000e+01,\n",
       "        2.58333333e+00, 1.55166667e+01, 5.73333333e+00, 2.57833333e+01,\n",
       "        3.06900000e+02, 4.22083333e+02, 3.08333333e+02, 5.36616667e+02,\n",
       "        1.74166667e+02, 1.92233333e+02, 3.06383333e+02, 3.19666667e+01,\n",
       "        1.35166667e+01, 1.06333333e+01, 2.01333333e+01]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data[\"X_night\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0285bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data[\"y_night\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc650834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_night\n",
      "\t X (55, 143)\n",
      "\t y (55,)\n",
      "\n",
      "time_day\n",
      "\t X (55, 179)\n",
      "\t y (55,)\n",
      "\n",
      "time_all\n",
      "\t X (55, 322)\n",
      "\t y (55,)\n",
      "\n",
      "freq_night\n",
      "\t X (55, 143)\n",
      "\t y (55,)\n",
      "\n",
      "freq_day\n",
      "\t X (55, 179)\n",
      "\t y (55,)\n",
      "\n",
      "freq_all\n",
      "\t X (55, 322)\n",
      "\t y (55,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for domain in [\"time\", \"freq\"]:\n",
    "    for part in [\"night\", \"day\", \"all\"]:\n",
    "        X = data[domain][\"X_\" + part]\n",
    "        y = data[domain][\"y_\" + part]\n",
    "        name = domain + \"_\" + part\n",
    "        print(name)\n",
    "        print(\"\\t\", \"X\", X.shape)\n",
    "        print(\"\\t\", \"y\", y.shape)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da9b8b",
   "metadata": {},
   "source": [
    "Check for possible missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "425be4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time X_night True\n",
      "Time X_day False\n",
      "Time X_all True\n",
      "\n",
      "Frequency X_night True\n",
      "Frequency X_day False\n",
      "Frequency X_all True\n"
     ]
    }
   ],
   "source": [
    "for arr_name in [\"X_night\", \"X_day\", \"X_all\"]:\n",
    "    X = time_data[arr_name]\n",
    "    print(\"Time\", arr_name, np.any(np.isnan(X)))\n",
    "    \n",
    "print()\n",
    "    \n",
    "for arr_name in [\"X_night\", \"X_day\", \"X_all\"]:\n",
    "    X = freq_data[arr_name]\n",
    "    print(\"Frequency\", arr_name, np.any(np.isnan(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5695e08",
   "metadata": {},
   "source": [
    "We have some missing values. However, we'll not remove them, unlike in the paper, since Numpy and Scipy allow as to operate on arrays with missing values using special functions, e.g. `np.nanmean()` or `np.nanstd()`. Arrays have to have the same number of columns for each for, so if we wanted to actually remove those values we would have to either go back to lists of arrays (slow and code would be ugly) or remove columns from all measurements (wasteful)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a061daf",
   "metadata": {},
   "source": [
    "Standardization is done during calculation of features. This is because the mean is one of the features and calculating it after standardization wouldn't make sense (it's always 0 then)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23f2ee",
   "metadata": {},
   "source": [
    "### Time domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816da09",
   "metadata": {},
   "source": [
    "Time features are extracted according to the article:\n",
    "- `mean`, `median`, `stddev`, `variance`, `kurtosis`, `minimum`, `maximum` - quite self explanatory statistical features\n",
    "- `coeff_of_var` - coefficient of variation, the ratio of the biased standard deviation to the mean\n",
    "- `iqr` - interquartile range, difference between 75 and 25 percentile (3rd and 1st quartile)\n",
    "- `trimmed_mean` - alternatively truncated mean, mean of the values where the most extreme values (from both ends) are not used; since the article doesn't specify this, I assume that the popular 10% trim percentage is used\n",
    "\n",
    "Data is saved as a DataFrame, since some machine learning models can provide additional insight when using named columns.\n",
    "\n",
    "Multiple features are calculated before standardization, since they wouldn't make sense for standardized data, when mean and standard deviation are always 0 and 1, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41c739cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr, kurtosis, trim_mean, variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38031b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(X: np.ndarray) -> pd.DataFrame:\n",
    "    # features for non-standardized data\n",
    "    mean = np.nanmean(X, axis=1)\n",
    "    median = np.nanmedian(X, axis=1)\n",
    "    stddev = np.nanstd(X, axis=1, ddof=1)  # paper divides by (N - 1)\n",
    "    var = np.nanvar(X, axis=1)\n",
    "    kurt = kurtosis(X, axis=1, nan_policy=\"omit\")\n",
    "    coeff_of_var = variation(X, axis=1, nan_policy=\"omit\")\n",
    "    iq_range = iqr(X, axis=1, nan_policy=\"omit\")\n",
    "    minimum = np.nanmin(X, axis=1)\n",
    "    maximum = np.nanmax(X, axis=1)\n",
    "    \n",
    "    # Scipy doesn't have NaN option for trimmed mean, so we have to calculate it by hand\n",
    "    trimmed_mean = np.array([trim_mean(row[~np.isnan(row)], proportiontocut=0.1) for row in X])\n",
    "    \n",
    "    features = {\n",
    "        \"mean\": mean,\n",
    "        \"median\": median,\n",
    "        \"stddev\": stddev,\n",
    "        \"variance\": var,\n",
    "        \"kurtosis\": kurt,\n",
    "        \"coeff_of_var\": coeff_of_var,\n",
    "        \"iqr\": iq_range,\n",
    "        \"minimum\": minimum,\n",
    "        \"maximum\": maximum,\n",
    "        \"trimmed_mean\": trimmed_mean\n",
    "    }\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46dd3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = {}\n",
    "\n",
    "for arr_name in [\"X_night\", \"X_day\", \"X_all\"]:\n",
    "    time_features[arr_name] = extract_time_features(time_data[arr_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f0e9473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>stddev</th>\n",
       "      <th>variance</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>coeff_of_var</th>\n",
       "      <th>iqr</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>trimmed_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.117133</td>\n",
       "      <td>11.583333</td>\n",
       "      <td>45.756484</td>\n",
       "      <td>2079.014907</td>\n",
       "      <td>2.416487</td>\n",
       "      <td>1.336461</td>\n",
       "      <td>46.425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.883333</td>\n",
       "      <td>24.915652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.121096</td>\n",
       "      <td>23.633333</td>\n",
       "      <td>158.228121</td>\n",
       "      <td>24861.060346</td>\n",
       "      <td>2.792222</td>\n",
       "      <td>1.514332</td>\n",
       "      <td>74.825</td>\n",
       "      <td>2.183333</td>\n",
       "      <td>763.416667</td>\n",
       "      <td>69.512609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.023893</td>\n",
       "      <td>30.216667</td>\n",
       "      <td>122.794729</td>\n",
       "      <td>14973.101020</td>\n",
       "      <td>1.478461</td>\n",
       "      <td>1.344313</td>\n",
       "      <td>120.350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>502.316667</td>\n",
       "      <td>66.538551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.998834</td>\n",
       "      <td>30.916667</td>\n",
       "      <td>104.402483</td>\n",
       "      <td>10823.655597</td>\n",
       "      <td>3.200870</td>\n",
       "      <td>1.284423</td>\n",
       "      <td>106.900</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>532.350000</td>\n",
       "      <td>60.698696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136.699650</td>\n",
       "      <td>65.516667</td>\n",
       "      <td>149.172041</td>\n",
       "      <td>22096.687197</td>\n",
       "      <td>0.899069</td>\n",
       "      <td>1.087417</td>\n",
       "      <td>229.350</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>666.816667</td>\n",
       "      <td>113.303333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean     median      stddev      variance  kurtosis  coeff_of_var  \\\n",
       "0   34.117133  11.583333   45.756484   2079.014907  2.416487      1.336461   \n",
       "1  104.121096  23.633333  158.228121  24861.060346  2.792222      1.514332   \n",
       "2   91.023893  30.216667  122.794729  14973.101020  1.478461      1.344313   \n",
       "3   80.998834  30.916667  104.402483  10823.655597  3.200870      1.284423   \n",
       "4  136.699650  65.516667  149.172041  22096.687197  0.899069      1.087417   \n",
       "\n",
       "       iqr   minimum     maximum  trimmed_mean  \n",
       "0   46.425  0.000000  206.883333     24.915652  \n",
       "1   74.825  2.183333  763.416667     69.512609  \n",
       "2  120.350  0.000000  502.316667     66.538551  \n",
       "3  106.900  0.416667  532.350000     60.698696  \n",
       "4  229.350  2.533333  666.816667    113.303333  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_features[\"X_night\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8cdc6",
   "metadata": {},
   "source": [
    "### Frequency domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081250a7",
   "metadata": {},
   "source": [
    "Time features are extracted according to the article:\n",
    "- all of the features that were calculated for time domain\n",
    "- entropy\n",
    "- skewness\n",
    "- spectral flatness\n",
    "\n",
    "Also the \"Spectral Density\" feature has been interpreted as total average power, i.e. simply the sum for the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68de52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e92aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_flatness(X: np.ndarray) -> np.ndarray:    \n",
    "    # normalizing factor for each row: 1/N * sum(x)\n",
    "    norm = X.mean()\n",
    "    if norm == 0:\n",
    "        norm = 1\n",
    "    \n",
    "    X = np.log(X + 1e-20)  # add small number to avoid infinities\n",
    "    X = np.exp(X.mean()) / norm\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "153a45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_freq_features(X: np.ndarray) -> pd.DataFrame:\n",
    "    # features for non-standardized data\n",
    "    mean = np.nanmean(X, axis=1)\n",
    "    median = np.nanmedian(X, axis=1)\n",
    "    stddev = np.nanstd(X, axis=1, ddof=1)  # paper divides by (N - 1)\n",
    "    var = np.nanvar(X, axis=1)\n",
    "    kurt = kurtosis(X, axis=1, nan_policy=\"omit\")\n",
    "    coeff_of_var = variation(X, axis=1, nan_policy=\"omit\")\n",
    "    iq_range = iqr(X, axis=1, nan_policy=\"omit\")\n",
    "    minimum = np.nanmin(X, axis=1)\n",
    "    maximum = np.nanmax(X, axis=1)\n",
    "    \n",
    "    # Scipy doesn't have NaN option for trimmed mean or entropy, so we have to calculate them by hand\n",
    "    trimmed_mean = np.array([trim_mean(row[~np.isnan(row)], proportiontocut=0.1) for row in X])\n",
    "    \n",
    "    spectral_density = np.nansum(X, axis=1)\n",
    "    skewness = skew(X, axis=1, nan_policy=\"omit\")\n",
    "    entr = np.array([entropy(row[~np.isnan(row)], base=2) for row in X])\n",
    "    flatness = np.array([spectral_flatness(row[~np.isnan(row)]) for row in X])\n",
    "\n",
    "    features = {\n",
    "        \"mean\": mean,\n",
    "        \"median\": median,\n",
    "        \"stddev\": stddev,\n",
    "        \"variance\": var,\n",
    "        \"kurtosis\": kurt,\n",
    "        \"coeff_of_var\": coeff_of_var,\n",
    "        \"iqr\": iq_range,\n",
    "        \"minimum\": minimum,\n",
    "        \"maximum\": maximum,\n",
    "        \"trimmed_mean\": trimmed_mean,\n",
    "        \"spectral_density\": spectral_density,\n",
    "        \"skewness\": skewness,\n",
    "        \"entropy\": entr,\n",
    "        \"spectral_flatness\": flatness\n",
    "    }\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2b335174",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_features = {}\n",
    "\n",
    "for arr_name in [\"X_night\", \"X_day\", \"X_all\"]:\n",
    "    freq_features[arr_name] = extract_freq_features(freq_data[arr_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "feb9a8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>stddev</th>\n",
       "      <th>variance</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>coeff_of_var</th>\n",
       "      <th>iqr</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>trimmed_mean</th>\n",
       "      <th>spectral_density</th>\n",
       "      <th>skewness</th>\n",
       "      <th>entropy</th>\n",
       "      <th>spectral_flatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.117133</td>\n",
       "      <td>11.583333</td>\n",
       "      <td>45.756484</td>\n",
       "      <td>2079.014907</td>\n",
       "      <td>2.416487</td>\n",
       "      <td>1.336461</td>\n",
       "      <td>46.425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.883333</td>\n",
       "      <td>24.915652</td>\n",
       "      <td>4878.750000</td>\n",
       "      <td>1.744960</td>\n",
       "      <td>6.114835</td>\n",
       "      <td>0.014998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.121096</td>\n",
       "      <td>23.633333</td>\n",
       "      <td>158.228121</td>\n",
       "      <td>24861.060346</td>\n",
       "      <td>2.792222</td>\n",
       "      <td>1.514332</td>\n",
       "      <td>74.825</td>\n",
       "      <td>2.183333</td>\n",
       "      <td>763.416667</td>\n",
       "      <td>69.512609</td>\n",
       "      <td>14889.316667</td>\n",
       "      <td>1.871353</td>\n",
       "      <td>5.923931</td>\n",
       "      <td>0.358771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.023893</td>\n",
       "      <td>30.216667</td>\n",
       "      <td>122.794729</td>\n",
       "      <td>14973.101020</td>\n",
       "      <td>1.478461</td>\n",
       "      <td>1.344313</td>\n",
       "      <td>120.350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>502.316667</td>\n",
       "      <td>66.538551</td>\n",
       "      <td>13016.416667</td>\n",
       "      <td>1.539269</td>\n",
       "      <td>6.030191</td>\n",
       "      <td>0.039675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.998834</td>\n",
       "      <td>30.916667</td>\n",
       "      <td>104.402483</td>\n",
       "      <td>10823.655597</td>\n",
       "      <td>3.200870</td>\n",
       "      <td>1.284423</td>\n",
       "      <td>106.900</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>532.350000</td>\n",
       "      <td>60.698696</td>\n",
       "      <td>11582.833333</td>\n",
       "      <td>1.797638</td>\n",
       "      <td>6.169682</td>\n",
       "      <td>0.363638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136.699650</td>\n",
       "      <td>65.516667</td>\n",
       "      <td>149.172041</td>\n",
       "      <td>22096.687197</td>\n",
       "      <td>0.899069</td>\n",
       "      <td>1.087417</td>\n",
       "      <td>229.350</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>666.816667</td>\n",
       "      <td>113.303333</td>\n",
       "      <td>19548.050000</td>\n",
       "      <td>1.209742</td>\n",
       "      <td>6.351476</td>\n",
       "      <td>0.435199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean     median      stddev      variance  kurtosis  coeff_of_var  \\\n",
       "0   34.117133  11.583333   45.756484   2079.014907  2.416487      1.336461   \n",
       "1  104.121096  23.633333  158.228121  24861.060346  2.792222      1.514332   \n",
       "2   91.023893  30.216667  122.794729  14973.101020  1.478461      1.344313   \n",
       "3   80.998834  30.916667  104.402483  10823.655597  3.200870      1.284423   \n",
       "4  136.699650  65.516667  149.172041  22096.687197  0.899069      1.087417   \n",
       "\n",
       "       iqr   minimum     maximum  trimmed_mean  spectral_density  skewness  \\\n",
       "0   46.425  0.000000  206.883333     24.915652       4878.750000  1.744960   \n",
       "1   74.825  2.183333  763.416667     69.512609      14889.316667  1.871353   \n",
       "2  120.350  0.000000  502.316667     66.538551      13016.416667  1.539269   \n",
       "3  106.900  0.416667  532.350000     60.698696      11582.833333  1.797638   \n",
       "4  229.350  2.533333  666.816667    113.303333      19548.050000  1.209742   \n",
       "\n",
       "    entropy  spectral_flatness  \n",
       "0  6.114835           0.014998  \n",
       "1  5.923931           0.358771  \n",
       "2  6.030191           0.039675  \n",
       "3  6.169682           0.363638  \n",
       "4  6.351476           0.435199  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_features[\"X_night\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683e063",
   "metadata": {},
   "source": [
    "### Datasets with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f26ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_night = pd.merge(\n",
    "    time_features[\"X_night\"],\n",
    "    freq_features[\"X_night\"],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=[\"_time\", \"_freq\"]\n",
    ")\n",
    "\n",
    "X_day = pd.merge(\n",
    "    time_features[\"X_day\"],\n",
    "    freq_features[\"X_day\"],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=[\"_time\", \"_freq\"]\n",
    ")\n",
    "\n",
    "X_all = pd.merge(\n",
    "    time_features[\"X_all\"],\n",
    "    freq_features[\"X_all\"],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=[\"_time\", \"_freq\"]\n",
    ")\n",
    "\n",
    "y_night = time_data[\"y_night\"]\n",
    "y_day = time_data[\"y_day\"]\n",
    "y_all = time_data[\"y_all\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6884c1a",
   "metadata": {},
   "source": [
    "Standardize the data (called \"scaling\" or \"standard scaling\" in Scikit-learn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a3384ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0114e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_night_stand = scale(X_night)\n",
    "X_day_stand = scale(X_day)\n",
    "X_all_stand = scale(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a9dbf",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79474f3f",
   "metadata": {},
   "source": [
    "For selecting the best sets of features (from 1 to 9 features, depending on an experiment) the paper uses:\n",
    "- forward selection as the selection algorithm\n",
    "- logistic regression as a base estimator\n",
    "- 70%-30% of data for training-validation split\n",
    "\n",
    "While it's not explicitly stated, we assume that cross validation is used, since the number of patients is very low and it's also used later in the Random Forest (there it's written explicitly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dad6f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3f2346c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = ShuffleSplit(test_size=0.3, random_state=0)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "forward_selector = SequentialFeatureSelector(\n",
    "    clf,\n",
    "    n_features_to_select=9,\n",
    "    direction=\"forward\",\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cross_validator,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b3a48274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_time', 'median_time', 'iqr_time', 'maximum_time',\n",
       "       'trimmed_mean_time', 'mean_freq', 'median_freq', 'iqr_freq',\n",
       "       'trimmed_mean_freq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_selector.fit(X_night_stand, y_night)\n",
    "night_features = X_night.columns[forward_selector.get_support()]\n",
    "night_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d35535",
   "metadata": {},
   "source": [
    "Paper features for night: kurtosis (time), median (time), interquartil rank (time), minimum (time), maximum (time), median (frequency), standard deviation (frequency), coefficient of variance (frequency), spectral flatness (frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed87b933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_time', 'median_time', 'variance_time', 'coeff_of_var_time',\n",
       "       'iqr_time', 'mean_freq', 'variance_freq', 'coeff_of_var_freq',\n",
       "       'entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_selector.fit(X_day_stand, y_night)\n",
    "day_features = X_day.columns[forward_selector.get_support()]\n",
    "day_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3cd372",
   "metadata": {},
   "source": [
    "Paper features for day: kurtosis (time), mean (time), median (time), minimum (time), trim mean (time), median (frequency), standard deviation (frequency), coefficient of variance (frequency), spectral flatness (frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "770edf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_time', 'median_time', 'stddev_time', 'variance_time',\n",
       "       'coeff_of_var_time', 'median_freq', 'stddev_freq', 'skewness',\n",
       "       'entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_selector.fit(X_all_stand, y_night)\n",
    "all_features = X_all.columns[forward_selector.get_support()]\n",
    "all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a33586",
   "metadata": {},
   "source": [
    "Paper features for full day: kurtosis (time), median (time), coefficient of variance (time), minimum (time), trim mean (time), median (frequency), standard deviation (frequency), coefficient of variance (frequency), spectral flatness (frequency)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe4a55",
   "metadata": {},
   "source": [
    "In all cases features differ quite a lot from those in the paper. Let's check performance of features selected above and those from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e5e09",
   "metadata": {},
   "source": [
    "## Random Forest training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c30b96",
   "metadata": {},
   "source": [
    "Since we are using Random Forest, no hyperparameter tuning is performed. Because of very small sample size, instead of choosing a single test set, we opt for cross validation. While this is certainly a controversial choice, there are good reasons for it:\n",
    "- small sample size would make a single test set not very meaningful, since its generalization approximation would not be very good\n",
    "- with no hyperparameter tuning, the validation set can be treated as a test set, since it's independent of the classifier\n",
    "- instead of single accuracy measure, which could be misleading with such small sample size, we get multiple accuracies and can check mean accuracy and standard deviation; if the latter turns out higher, then it would mean that results depend largely on randomly chosen test set (this problem arises because of small sample size)\n",
    "\n",
    "We measure 2 different cross validation sizes:\n",
    "- 3-fold cross validation, to be as close as possible to the 30% test set from the paper\n",
    "- 5-fold cross validation, to have better overwiew of how accuracy changes with different folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27dbe19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "79a301b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_night_selected = X_night[night_features]\n",
    "X_day_selected = X_day[day_features]\n",
    "X_all_selected = X_all[all_features]\n",
    "\n",
    "X_night_paper = X_night[[\n",
    "    \"kurtosis_time\", \"median_time\", \"iqr_time\", \"minimum_time\",\n",
    "    \"maximum_time\", \"median_freq\", \"stddev_freq\", \"coeff_of_var_freq\",\n",
    "    \"spectral_flatness\"\n",
    "]]\n",
    "\n",
    "X_day_paper = X_day[[\n",
    "    \"kurtosis_time\", \"mean_time\", \"median_time\", \"minimum_time\",\n",
    "    \"trimmed_mean_time\", \"median_freq\", \"stddev_freq\", \"coeff_of_var_freq\",\n",
    "    \"spectral_flatness\"\n",
    "]]\n",
    "\n",
    "X_all_paper = X_all[[\n",
    "    \"kurtosis_time\", \"median_time\", \"coeff_of_var_time\", \"minimum_time\",\n",
    "    \"trimmed_mean_time\", \"median_freq\", \"stddev_freq\", \"coeff_of_var_freq\",\n",
    "    \"spectral_flatness\"\n",
    "]]\n",
    "\n",
    "Xs = {\n",
    "    \"night\": (X_night_selected, X_night_paper),\n",
    "    \"day\": (X_day_selected, X_day_paper),\n",
    "    \"all\": (X_all_selected, X_all_paper)\n",
    "}\n",
    "\n",
    "ys = {\"night\": y_night, \"day\": y_day, \"all\": y_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ccfd1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, max_features=\"sqrt\", n_jobs=-1, random_state=0)\n",
    "results = {}\n",
    "\n",
    "for part in [\"night\", \"day\", \"all\"]:\n",
    "    X_selected, X_paper = Xs[part]\n",
    "    y = ys[part]\n",
    "    \n",
    "    selected_results_3 = cross_val_score(clf, X_selected, y, scoring=\"accuracy\", cv=3)\n",
    "    selected_results_5 = cross_val_score(clf, X_selected, y, scoring=\"accuracy\", cv=5)\n",
    "    \n",
    "    paper_results_3 = cross_val_score(clf, X_paper, y, scoring=\"accuracy\", cv=3)\n",
    "    paper_results_5 = cross_val_score(clf, X_paper, y, scoring=\"accuracy\", cv=5)\n",
    "    \n",
    "    results[part] = {3: [selected_results_3, paper_results_3], 5: [selected_results_5, paper_results_5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e5d3160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_raport(cv_results: np.ndarray) -> None:\n",
    "    result = f\"accuracy: {cv_results.mean():.2f} Â± {np.std(cv_results):.2f}, \"\n",
    "    result += f\"min: {cv_results.min():.2f}, \"\n",
    "    result += f\"max: {cv_results.max():.2f}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "02faa983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIGHT\n",
      "\t 3 folds, selected: accuracy: 0.80 Â± 0.14, min: 0.61, max: 0.94\n",
      "\t 3 folds, paper: accuracy: 0.73 Â± 0.16, min: 0.56, max: 0.94\n",
      "\n",
      "\t 5 folds, selected: accuracy: 0.75 Â± 0.15, min: 0.64, max: 1.00\n",
      "\t 5 folds, paper: accuracy: 0.75 Â± 0.16, min: 0.55, max: 1.00\n",
      "\n",
      "\n",
      "DAY\n",
      "\t 3 folds, selected: accuracy: 0.73 Â± 0.07, min: 0.67, max: 0.83\n",
      "\t 3 folds, paper: accuracy: 0.66 Â± 0.13, min: 0.53, max: 0.83\n",
      "\n",
      "\t 5 folds, selected: accuracy: 0.71 Â± 0.07, min: 0.64, max: 0.82\n",
      "\t 5 folds, paper: accuracy: 0.64 Â± 0.18, min: 0.36, max: 0.91\n",
      "\n",
      "\n",
      "ALL\n",
      "\t 3 folds, selected: accuracy: 0.71 Â± 0.13, min: 0.58, max: 0.89\n",
      "\t 3 folds, paper: accuracy: 0.75 Â± 0.06, min: 0.68, max: 0.83\n",
      "\n",
      "\t 5 folds, selected: accuracy: 0.65 Â± 0.23, min: 0.27, max: 0.91\n",
      "\t 5 folds, paper: accuracy: 0.71 Â± 0.18, min: 0.45, max: 0.91\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for part in [\"night\", \"day\", \"all\"]:\n",
    "    selected_results_3, paper_results_3 = results[part][3]\n",
    "    selected_results_5, paper_results_5 = results[part][5]\n",
    "    \n",
    "    print(part.upper())\n",
    "    print(\"\\t\", \"3 folds, selected:\", get_cv_raport(selected_results_3))\n",
    "    print(\"\\t\", \"3 folds, paper:\", get_cv_raport(paper_results_3))\n",
    "    print()\n",
    "    print(\"\\t\", \"5 folds, selected:\", get_cv_raport(selected_results_5))\n",
    "    print(\"\\t\", \"5 folds, paper:\", get_cv_raport(paper_results_5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756bc5ae",
   "metadata": {},
   "source": [
    "Features from our selection performed generally better, only exception being all day data with 5-fold cross validation.\n",
    "\n",
    "There is very high standard deviation apparent in all cases, especially for night data. For all datasets results vary from unacceptably low (e.g. 56% on night 3-fold, 36% on day 5-fold), to exceptionally good (100% on 5-fold night). This makes us highly doubt results from the paper, which does not precisely state the testing procedure. It's apparent that on such small dataset even properly, randomly chosen test set is not enough to measure quality of the classifier.\n",
    "\n",
    "What's interesting is that on 5-fold cross validation we actually get worse results than on 3-fold, despite larget training set. This may also be attributed to very small dataset - samples randomly chosen to be in the validation set (which equals test set here) may be very different than those on the training set. This actually justifies the relatively high size of the test set from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f432d4a",
   "metadata": {},
   "source": [
    "## Random Forest with class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026047b",
   "metadata": {},
   "source": [
    "We have a noticeable class imbalance, so maybe using Random Forest with balanced class weights (using count of samples from each class) can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6b2dea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, max_features=\"sqrt\", class_weight=\"balanced\", n_jobs=-1, random_state=0)\n",
    "results = {}\n",
    "\n",
    "for part in [\"night\", \"day\", \"all\"]:\n",
    "    X_selected, X_paper = Xs[part]\n",
    "    y = ys[part]\n",
    "    \n",
    "    selected_results_3 = cross_val_score(clf, X_selected, y, scoring=\"accuracy\", cv=3)\n",
    "    selected_results_5 = cross_val_score(clf, X_selected, y, scoring=\"accuracy\", cv=5)\n",
    "    \n",
    "    paper_results_3 = cross_val_score(clf, X_paper, y, scoring=\"accuracy\", cv=3)\n",
    "    paper_results_5 = cross_val_score(clf, X_paper, y, scoring=\"accuracy\", cv=5)\n",
    "    \n",
    "    results[part] = {3: [selected_results_3, paper_results_3], 5: [selected_results_5, paper_results_5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ca534546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIGHT\n",
      "\t 3 folds, selected: accuracy: 0.80 Â± 0.14, min: 0.61, max: 0.94\n",
      "\t 3 folds, paper: accuracy: 0.73 Â± 0.16, min: 0.56, max: 0.94\n",
      "\n",
      "\t 5 folds, selected: accuracy: 0.75 Â± 0.15, min: 0.64, max: 1.00\n",
      "\t 5 folds, paper: accuracy: 0.71 Â± 0.16, min: 0.55, max: 1.00\n",
      "\n",
      "\n",
      "DAY\n",
      "\t 3 folds, selected: accuracy: 0.71 Â± 0.09, min: 0.61, max: 0.83\n",
      "\t 3 folds, paper: accuracy: 0.62 Â± 0.08, min: 0.53, max: 0.72\n",
      "\n",
      "\t 5 folds, selected: accuracy: 0.73 Â± 0.08, min: 0.64, max: 0.82\n",
      "\t 5 folds, paper: accuracy: 0.64 Â± 0.17, min: 0.36, max: 0.91\n",
      "\n",
      "\n",
      "ALL\n",
      "\t 3 folds, selected: accuracy: 0.69 Â± 0.15, min: 0.53, max: 0.89\n",
      "\t 3 folds, paper: accuracy: 0.75 Â± 0.06, min: 0.68, max: 0.83\n",
      "\n",
      "\t 5 folds, selected: accuracy: 0.65 Â± 0.24, min: 0.27, max: 0.91\n",
      "\t 5 folds, paper: accuracy: 0.71 Â± 0.18, min: 0.45, max: 0.91\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for part in [\"night\", \"day\", \"all\"]:\n",
    "    selected_results_3, paper_results_3 = results[part][3]\n",
    "    selected_results_5, paper_results_5 = results[part][5]\n",
    "    \n",
    "    print(part.upper())\n",
    "    print(\"\\t\", \"3 folds, selected:\", get_cv_raport(selected_results_3))\n",
    "    print(\"\\t\", \"3 folds, paper:\", get_cv_raport(paper_results_3))\n",
    "    print()\n",
    "    print(\"\\t\", \"5 folds, selected:\", get_cv_raport(selected_results_5))\n",
    "    print(\"\\t\", \"5 folds, paper:\", get_cv_raport(paper_results_5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667e994",
   "metadata": {},
   "source": [
    "Nothing really changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cba60",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793ba0b",
   "metadata": {},
   "source": [
    "As our second classifier we opted for SVM, since it's often used for ML in medicine and performs well for small datasets. It requires hyperparameter tuning, therefore we perform a following procedure to ensure proper results:\n",
    "- perform process similar to 3-fold cross-validation, splitting the dataset into 3 parts (after shuffling)\n",
    "- for each fold, take the current fold as a test set, and train classifier on the training set with leave-one-out cross validation\n",
    "\n",
    "While this approach has high computational requirements because of the leave-one-out cross-validation, we believe it is the only reasonable way to tune this type of classifier on such a small sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2b91e07d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, LeaveOneOut\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f42798d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(cv_n_splits):\n",
    "    cv_kfold = KFold(n_splits=cv_n_splits, shuffle=True, random_state=0)\n",
    "    cv_loo = LeaveOneOut()\n",
    "\n",
    "    clf = SVC(kernel=\"rbf\", cache_size=1024, random_state=0)\n",
    "\n",
    "    param_grid = {\n",
    "        \"C\": [1, 10, 20, 50, 100, 200, 500, 1000],\n",
    "        \"gamma\": [1e-4, 1e-3, 1e-2, 1e-1, \"scale\", \"auto\"]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=cv_loo)\n",
    "\n",
    "    results = {}\n",
    "    for part in [\"night\", \"day\", \"all\"]:\n",
    "        X_selected, X_paper = Xs[part]\n",
    "        X_selected, X_paper = X_selected.values, X_paper.values\n",
    "        y = ys[part]\n",
    "\n",
    "        accuracies = {\"selected\": [], \"paper\": []}\n",
    "        \n",
    "        for version, X in [(\"selected\", X_selected), (\"paper\", X_paper)]:\n",
    "            for train_idxs, test_idxs in cv_kfold.split(X):\n",
    "                \n",
    "                X_train, X_test = X[train_idxs], X[test_idxs]\n",
    "                y_train, y_test = y[train_idxs], y[test_idxs]\n",
    "\n",
    "                best_clf = grid_search.fit(X_train, y_train)\n",
    "                test_acc = accuracy_score(y_test, best_clf.predict(X_test))\n",
    "                accuracies[version].append(test_acc)\n",
    "\n",
    "        results[part] = accuracies\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a647b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_svm(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "35cd377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIGHT\n",
      "\t selected: accuracy: 0.63 Â± 0.08, min: 0.56, max: 0.74\n",
      "\t paper: accuracy: 0.64 Â± 0.02, min: 0.61, max: 0.67\n",
      "\n",
      "\n",
      "DAY\n",
      "\t selected: accuracy: 0.60 Â± 0.07, min: 0.50, max: 0.67\n",
      "\t paper: accuracy: 0.62 Â± 0.11, min: 0.47, max: 0.72\n",
      "\n",
      "\n",
      "ALL\n",
      "\t selected: accuracy: 0.67 Â± 0.10, min: 0.56, max: 0.79\n",
      "\t paper: accuracy: 0.63 Â± 0.08, min: 0.56, max: 0.74\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for part in [\"night\", \"day\", \"all\"]:\n",
    "    selected_results, paper_results = results[part][\"selected\"], results[part][\"paper\"]\n",
    "    selected_results, paper_results = np.array(selected_results), np.array(paper_results)\n",
    "    \n",
    "    print(part.upper())\n",
    "    print(\"\\t\", \"selected:\", get_cv_raport(selected_results))\n",
    "    print(\"\\t\", \"paper:\", get_cv_raport(paper_results))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ac0b6",
   "metadata": {},
   "source": [
    "SVM performance is noticably worse than Random Forest. The only positive is that standard deviations are much lower.\n",
    "\n",
    "Perhaps the 3-fold cross-validation is too harsh for a classifier that requires hyperparameter tuning. Let's check 5-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9a027026",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_svm(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d004cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIGHT\n",
      "\t selected: accuracy: 0.71 Â± 0.04, min: 0.64, max: 0.73\n",
      "\t paper: accuracy: 0.65 Â± 0.07, min: 0.55, max: 0.73\n",
      "\n",
      "\n",
      "DAY\n",
      "\t selected: accuracy: 0.55 Â± 0.08, min: 0.45, max: 0.64\n",
      "\t paper: accuracy: 0.56 Â± 0.16, min: 0.27, max: 0.73\n",
      "\n",
      "\n",
      "ALL\n",
      "\t selected: accuracy: 0.65 Â± 0.11, min: 0.55, max: 0.82\n",
      "\t paper: accuracy: 0.65 Â± 0.07, min: 0.55, max: 0.73\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for part in [\"night\", \"day\", \"all\"]:\n",
    "    selected_results, paper_results = results[part][\"selected\"], results[part][\"paper\"]\n",
    "    selected_results, paper_results = np.array(selected_results), np.array(paper_results)\n",
    "    \n",
    "    print(part.upper())\n",
    "    print(\"\\t\", \"selected:\", get_cv_raport(selected_results))\n",
    "    print(\"\\t\", \"paper:\", get_cv_raport(paper_results))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997ea76",
   "metadata": {},
   "source": [
    "On some parts we got slight improvements, on others classifier performed slightly worse. Overall, SVM is still heavily underperforming compared to Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72248049",
   "metadata": {},
   "source": [
    "## Overall results and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539778f9",
   "metadata": {},
   "source": [
    "The main conclusion from all experiments is that paper results are irreproducible, and such high performance has been achieved due to very small dataset and all problems that stem from it.\n",
    "\n",
    "The approach presented there has not been properly corrected to take into accounts all the anomalies that occur while using ML algorithms on small samples, e.g. the single test set is not a good approximation of the generalization performance of the classifier. Our analysis performed above shows in detail how skewed can the results be, even when using techniques that are sufficient for typical, larget datasets.\n",
    "\n",
    "While we were able to achieve the results close to 100% accuracy, their consistency cannot be guaranteed. The overall approach of using sensor data for mental health diagnosis, however, shows great potential. All accuracies have been high enough to justify cautious optimism, but small dataset size remain.\n",
    "\n",
    "When enough data is gathered (at least hundreds of samples for each class), then this unique approach to depression detection can be fully utilized in real world systems. We agree with the paper about gathering exclusively night data - it showed best results also on our tests, and it is the cheapest and easiest to measure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
